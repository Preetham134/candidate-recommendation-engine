![App Preview](https://github.com/Preetham134/candidate-recommendation-engine/blob/main/Engine.png)
![App Preview](https://github.com/Preetham134/candidate-recommendation-engine/blob/main/Summaries.png)

# üîç Candidate Recommendation Engine

A powerful AI-powered web application that takes in a **Job Description** and multiple **PDF Resumes**, and returns the **Top Matching Candidates** ranked by semantic relevance, along with **LLM-generated fit summaries**. Built using `Streamlit`, `Sentence Transformers`, `LLaMA 3`, and `Pinecone`.

---

## üìö Table of Contents

- [üöÄ Overview](#-overview)
- [üß† Tech Stack](#-tech-stack)
- [üèóÔ∏è System Architecture](#-system-architecture)
- [‚öôÔ∏è Implementation Details](#Ô∏è-implementation-details)
- [üîÅ Workflow](#-workflow)
- [‚òÅÔ∏è Why Pinecone, Transformers, and LLMs?](#Ô∏è-why-pinecone-transformers-and-llms)
- [üåç Deployment Guide](#-deployment-guide)
- [üì¶ Requirements](#-requirements)
- [üìå Future Enhancements](#-future-enhancements)

---

## üöÄ Overview

This application helps recruiters, hiring managers, and HR professionals **automatically match candidates to job roles** by:

1. Extracting resume text from PDF files.
2. Computing semantic similarity scores between resumes and job descriptions using embeddings.
3. Ranking resumes using a **Pinecone-powered vector database**.
4. Generating natural language **AI fit summaries** using **LLaMA 3**.

It's built for scalability, fast processing, and high accuracy in candidate-job matching.

---

## üß† Tech Stack

| Layer            | Tools / Libraries                                      |
|------------------|--------------------------------------------------------|
| **Frontend**     | Streamlit (Python-based Web UI)                        |
| **Embedding**    | Sentence Transformers (`intfloat/e5-large-v2`)         |
| **Vector Search**| Pinecone                                                |
| **LLM Summary**  | LLaMA 3 (Meta) via HuggingFace                         |
| **PDF Parsing**  | PyMuPDF (`fitz`)                                       |
| **NER (Name)**   | spaCy (`en_core_web_sm`)                               |
| **Deployment**   | Ngrok (for local tunneling) / Streamlit Share / AWS    |

---

## üèóÔ∏è System Architecture

```plaintext
[User Uploads]
  ‚îú‚îÄ‚îÄ Job Description (.txt)
  ‚îî‚îÄ‚îÄ Resume PDFs (.pdf)
         ‚Üì
 [Text Extraction]
  ‚îú‚îÄ‚îÄ extract_text_from_pdf()
  ‚îî‚îÄ‚îÄ extract_candidate_name()
         ‚Üì
 [Embedding Model: Sentence Transformers]
         ‚Üì
 [Pinecone Vector DB]
  ‚îú‚îÄ‚îÄ Upsert resume embeddings
  ‚îî‚îÄ‚îÄ Query top-K matches with job embedding
         ‚Üì
 [Ranking Output]
         ‚Üì
 [LLM (LLaMA-3) Fit Summary Generation]
         ‚Üì
 [Streamlit Frontend Display]
```

---

## ‚öôÔ∏è Implementation Details

### 1. **Text Extraction**  
`resume_parser.py` uses PyMuPDF to extract clean resume text and `spaCy` to estimate the candidate's name.

### 2. **Embeddings with Sentence Transformers**  
`embedding_utils.py` loads the `intfloat/e5-large-v2` model which supports the **"query: ..." and "passage: ..."** input format for better performance in information retrieval tasks.

### 3. **Resume Indexing**  
`matching.py::index_resumes_fresh()` clears previous embeddings and stores fresh ones in Pinecone. Metadata includes candidate name, filename, and raw text.

### 4. **Semantic Search with Pinecone**  
The job description is embedded and passed to Pinecone to retrieve **Top-K semantically similar resumes** using cosine similarity.

### 5. **Fit Summary Generation**  
`generate_batch_fit_summaries()` uses **Meta‚Äôs LLaMA 3 (3B)** hosted on Hugging Face to generate short, **factual, unbiased summaries** based purely on resume content.

---

## üîÅ Workflow

1. üìù Upload a **Job Description (.txt)**.
2. üìé Upload multiple **Resumes (.pdf)**.
3. üìä App embeds and indexes resumes via **Pinecone**.
4. üß† Job description is embedded and **Top-K candidates** are retrieved.
5. ü§ñ **LLM** generates a concise fit summary for each.
6. ‚úÖ Results are presented in the Streamlit UI.

> ‚ö†Ô∏è **Note**: Due to external latency (API, model loading, etc.), if you **change the Top-N value or upload new resumes or job descriptions**, results may not update immediately.  
> If you don‚Äôt see results, wait a few seconds and **try clicking "Process" again**. Avoid rapidly pressing the button.

---

## ‚òÅÔ∏è Why Pinecone, Transformers, and LLMs?

### ‚úÖ **Pinecone** ‚Äì *Scalable Vector Search*
- Handles **millions of high-dimensional vectors** with blazing speed.
- Offers **persistent storage**, so you don‚Äôt need to re-index every time.
- Allows **real-time retrieval** with configurable top-k matching.
- Offloads the complexity of managing your own similarity search infra (e.g., FAISS).
- Enables rapid prototyping **without infrastructure headaches**.

### ‚úÖ **Transformers (Sentence Transformers)** ‚Äì *Contextual Embedding*
- `intfloat/e5-large-v2` is **fine-tuned for search tasks** using contrastive learning.
- Captures **meaningful sentence-level semantics** over just keyword overlap.

### ‚úÖ **LLM (LLaMA 3)** ‚Äì *Natural Language Understanding*
- Can **summarize** large amounts of resume text into **short, factual fit reports**.
- Adds **explainability** behind semantic matches.

---

## üåç Deployment Guide

### ‚úÖ Local Setup

Only three steps:

```bash
# 1. Clone the repo
git clone https://github.com/your-username/candidate-recommender.git
cd candidate-recommender

# 2. Install dependencies
pip install -r requirements.txt

# 3. Run the app
streamlit run app.py
```

> ‚ö†Ô∏è **Note on Hosting**:
- Attempted hosting on **Streamlit Cloud**, but faced issues with **dependency resolution failures** (e.g., en_core_web_sm).
  Link: https://candidate-recommendation-engine-ngs2xkgms66oatrwtalkbo.streamlit.app/
- Tried other online providers, but **RAM limitations** (e.g., <4GB) were insufficient for LLaMA inference and embedding generation.
- **Local usage** with adequate memory and internet is currently **recommended**.

---

## üì¶ Requirements

All dependencies are listed in `requirements.txt`:

```text
streamlit
sentence-transformers
PyMuPDF
scikit-learn
spacy
torch
transformers
huggingface_hub
requests
langchain_community
accelerate
pinecone
```

Before running, ensure:

```bash
python -m spacy download en_core_web_sm
```

---

## üìå Future Enhancements

- üîÑ Add resume **chunking** to handle long documents (avoid embedding cutoffs).
- üìä Integrate **charts and analytics** to visually compare candidate scores.
- üìÉ Enable **CSV or PDF export** of results.
- üí¨ Add a **chatbot assistant** for recruiter queries (e.g., ‚ÄúWho is the strongest match?‚Äù).
- üß† Use **LangChain/LangGraph** to enrich or control LLM behavior more dynamically.
- üöÄ **Dockerize and deploy** on AWS/GCP/Azure for production readiness.
- üßµ **Reduce the number of LLM calls** (e.g., batch or cache summaries) to improve speed and cost.
